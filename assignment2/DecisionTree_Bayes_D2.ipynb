{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树分类器的准确率为: 0.9333333333333333\n",
      "决策树分类器的宏平均精确率为: 0.9305555555555555\n",
      "决策树分类器的微平均精确率为: 0.9333333333333333\n",
      "决策树分类器的宏平均召回率为: 0.9264957264957264\n",
      "决策树分类器的微平均召回率为: 0.9333333333333333\n",
      "决策树分类器的宏平均F1-score为: 0.927741935483871\n",
      "决策树分类器的微平均F1-score为: 0.9333333333333333\n",
      "混淆矩阵为:\n",
      " [[17  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:69: DeprecationWarning: scipy.sort is deprecated and will be removed in SciPy 2.0.0, use numpy.sort instead\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from scipy import *\n",
    "from math import log\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "#划分数据集\n",
    "def load_data(ratio):\n",
    "    data = pd.read_csv(\"D2.data\",header=None)\n",
    "    data_set = np.array(data).tolist()\n",
    "    train_data, test_data = train_test_split(data_set,test_size = ratio)\n",
    "    return train_data,test_data\n",
    " \n",
    "\n",
    "#决策树的生成\n",
    "def generate_decision_tree(data_set ,attribute_label):\n",
    "    label_list = [entry[-1] for entry in data_set]\n",
    "    if label_list.count(label_list[0]) == len(label_list): #如果所有的数据都属于同一个类别，则返回该类别\n",
    "        return label_list[0]\n",
    "    if len(data_set[0]) == 1: #如果数据没有属性值数据，则返回该其中出现最多的类别作为分类\n",
    "        return most_voted_attribute(label_list)\n",
    "    best_attribute_index, best_split_point = attribute_selection_method(data_set)\n",
    "    best_attribute = attribute_label[best_attribute_index]\n",
    "    decision_tree = { best_attribute:{}}\n",
    "    del(attribute_label[best_attribute_index]) #找到最佳划分属性后需要将其从属性名列表中删除\n",
    "\n",
    "    #如果best_split_point为空，说明此时最佳划分属性的类型为离散值，否则为连续值\n",
    "    if best_split_point == None:\n",
    "        attribute_list = [entry[best_attribute_index] for entry in data_set]\n",
    "        attribute_set = set(attribute_list)\n",
    "        for attribute in attribute_set: #属性的各个值\n",
    "            sub_labels = attribute_label[:]\n",
    "            decision_tree[best_attribute][attribute] = generate_decision_tree(\n",
    "                split_data_set(data_set,best_attribute_index,attribute,continuous=False),sub_labels)\n",
    "    else:\n",
    "        #最佳划分属性类型为连续值，此时计算出的最佳划分点将数据集一分为二，划分字段取名为<=和>\n",
    "        sub_labels = attribute_label[:]\n",
    "        decision_tree[best_attribute][\"<=\"+str(best_split_point)] = generate_decision_tree(\n",
    "            split_data_set(data_set, best_attribute_index, best_split_point, True, 0), sub_labels)\n",
    "        sub_labels = attribute_label[:]\n",
    "        decision_tree[best_attribute][\">\" + str(best_split_point)] = generate_decision_tree(\n",
    "            split_data_set(data_set, best_attribute_index, best_split_point, True, 1), sub_labels)\n",
    "    return decision_tree\n",
    " \n",
    "#通过信息增益比来计算最佳划分属性\n",
    "def attribute_selection_method(data_set):\n",
    "    num_attributes = len(data_set[0])-1 #属性的个数，减1是因为去掉了标签\n",
    "    info_D = calc_info_D(data_set)  #香农熵\n",
    "    max_grian_rate = 0.0  #最大信息增益比\n",
    "    best_attribute_index = -1\n",
    "    best_split_point = None\n",
    "    continuous = False\n",
    "    for i in range(num_attributes):\n",
    "        attribute_list = [entry[i] for entry in data_set]  # 求属性列表，此时为连续值\n",
    "        info_A_D = 0.0  #特征A对数据集D的信息增益\n",
    "        split_info_D = 0.0  #数据集D关于特征A的值的熵\n",
    "        if attribute_list[0] not in set(['M','F','I']):\n",
    "            continuous = True\n",
    "        \"\"\"\n",
    "        属性为连续值，先对该属性下的所有离散值进行排序\n",
    "        然后每相邻的两个值之间的中点作为划分点计算信息增益比，对应最大增益比的划分点为最佳划分点\n",
    "        由于可能多个连续值可能相同，所以通过set只保留其中一个值\n",
    "        \"\"\"\n",
    "        if continuous == True:\n",
    "            attribute_list = sort(attribute_list)\n",
    "            temp_set = set(attribute_list) #通过set来剔除相同的值\n",
    "            attribute_list = [attr for attr in temp_set]\n",
    "            split_points = []\n",
    "            for index in range(len(attribute_list) - 1):\n",
    "                #求出各个划分点\n",
    "                split_points.append((float(attribute_list[index]) + float(attribute_list[index + 1])) / 2)\n",
    "            for split_point in split_points:#对划分点进行遍历\n",
    "                info_A_D = 0.0\n",
    "                split_info_D = 0.0\n",
    "                for part in range(2): #最佳划分点将数据一分为二，因此循环2次即可得到两段数据\n",
    "                    sub_data_set = split_data_set(data_set, i, split_point, True, part)\n",
    "                    prob = len(sub_data_set) / float(len(data_set))\n",
    "                    info_A_D += prob * calc_info_D(sub_data_set)\n",
    "                    split_info_D -= prob * log(prob, 2)\n",
    "                if split_info_D==0:\n",
    "                    split_info_D+=1\n",
    "                \n",
    "                #由于关于属性A的熵split_info_D可能为0，因此此处加1\n",
    "                \n",
    "                grian_rate = (info_D - info_A_D) / split_info_D #计算信息增益比\n",
    "                if grian_rate > max_grian_rate:\n",
    "                    max_grian_rate = grian_rate\n",
    "                    best_split_point = split_point\n",
    "                    best_attribute_index = i\n",
    "                    #print([best_attribute_index,best_split_point])\n",
    "        else: #划分属性为离散值\n",
    "            attribute_list = [entry[i] for entry in data_set]  # 求属性列表\n",
    "            attribute_set = set(attribute_list)\n",
    "            for attribute in attribute_set: #对每个属性进行遍历\n",
    "                sub_data_set = split_data_set(data_set, i, attribute, False)\n",
    "                prob = len(sub_data_set) / float(len(data_set))\n",
    "                info_A_D += prob * calc_info_D(sub_data_set)\n",
    "                split_info_D -= prob * log(prob, 2)\n",
    "            if split_info_D == 0:\n",
    "                split_info_D += 1\n",
    "            grian_rate = (info_D - info_A_D) / split_info_D #计算信息增益比\n",
    "            if grian_rate > max_grian_rate:\n",
    "                max_grian_rate = grian_rate\n",
    "                # print(max_grian_rate)\n",
    "                best_attribute_index = i\n",
    "                best_split_point = None  #如果最佳属性是离散值，此处将分割点置为空留作判定\n",
    " \n",
    "    return best_attribute_index,best_split_point\n",
    " \n",
    "#多数表决：返回标签列表中数量最大的类\n",
    "def most_voted_attribute(label_list):\n",
    "    label_nums = {}\n",
    "    for label in label_list:\n",
    "        if label in label_nums.keys():\n",
    "            label_nums[label] += 1\n",
    "        else:\n",
    "            label_nums[label] = 1\n",
    "    sorted_label_nums = sorted(label_nums.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_label_nums[0][0]\n",
    " \n",
    "#计算信息熵\n",
    "def calc_info_D(data_set):\n",
    "    num_entries = len(data_set)\n",
    "    label_nums = {} #为每个类别建立字典，value为对应该类别的数目\n",
    "    for entry in data_set:\n",
    "        label = entry[-1]\n",
    "        if label in label_nums.keys():\n",
    "            label_nums[label]+=1\n",
    "        else:\n",
    "            label_nums[label]=1\n",
    "    info_D = 0.0\n",
    "    for label in label_nums.keys():\n",
    "        prob = float(label_nums[label])/num_entries\n",
    "        info_D -= prob * log(prob,2)\n",
    "    return info_D\n",
    " \n",
    "\n",
    "#按属性划分子数据集，分为离散属性的划分与连续属性的划分\n",
    "def split_data_set(data_set, index, value, continuous, part=0):\n",
    "    res_data_set = []\n",
    "    if continuous == True:#划分的属性为连续值\n",
    "        for entry in data_set:\n",
    "            if part == 0 and float(entry[index])<= value: #求划分点左侧的数据集\n",
    "                reduced_entry = entry[:index]\n",
    "                reduced_entry.extend(entry[index + 1:]) #划分后去除数据中第index列的值\n",
    "                res_data_set.append(reduced_entry)\n",
    "            if part ==1 and float(entry[index])> value: #求划分点右侧的数据集\n",
    "                reduced_entry = entry[:index]\n",
    "                reduced_entry.extend(entry[index + 1:])\n",
    "                res_data_set.append(reduced_entry)\n",
    " \n",
    "    else: #划分的属性为离散值\n",
    "        for entry in data_set:\n",
    "            if entry[index] == value: #按数据集中第index列的值等于value的分数据集\n",
    "                reduced_entry = entry[:index]\n",
    "                reduced_entry.extend(entry[index+1:]) #划分后去除数据中第index列的值\n",
    "                res_data_set.append(reduced_entry)\n",
    "    return res_data_set\n",
    " \n",
    "\n",
    "#对一项测试数据进行预测，通过递归来预测该项数据的标签\n",
    "def decision_tree_predict(decision_tree, attribute_labels, one_test_data):\n",
    "    first_key = list(decision_tree.keys())[0]\n",
    "    second_dic = decision_tree[first_key]\n",
    "    attribute_index = attribute_labels.index(first_key)\n",
    "    res_label = None\n",
    "    for key in second_dic.keys(): #属性分连续值和离散值，连续值对应<=和>两种情况\n",
    "        if key[0] == '<':\n",
    "            value = float(key[2:])\n",
    "            if float(one_test_data[attribute_index])<= value:\n",
    "                if type(second_dic[key]).__name__ =='dict':\n",
    "                    res_label = decision_tree_predict(second_dic[key], attribute_labels, one_test_data)\n",
    "                else:\n",
    "                    res_label = second_dic[key]\n",
    "        elif key[0] == '>':\n",
    "            #print(key[1:])\n",
    "            value = float(key[1:])\n",
    "            if float(one_test_data[attribute_index]) > value:\n",
    "                if type(second_dic[key]).__name__ == 'dict':\n",
    "                    res_label = decision_tree_predict(second_dic[key], attribute_labels, one_test_data)\n",
    "                else:\n",
    "                    res_label = second_dic[key]\n",
    " \n",
    "        else:\n",
    "            if one_test_data[attribute_index] == key:\n",
    "                if type(second_dic[key]).__name__ =='dict':\n",
    "                    res_label = decision_tree_predict(second_dic[key], attribute_labels, one_test_data)\n",
    "                else:\n",
    "                    res_label = second_dic[key]\n",
    "    return res_label\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    ratio = 0.3 #测试集的比例\n",
    "    train_data, test_data =load_data(ratio)\n",
    "    attribute_label = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "    decision_tree= generate_decision_tree(train_data,attribute_label)\n",
    "    #递归会改变attribute_label的值，此处再传一次\n",
    "    attribute_label = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "    count = 0\n",
    "    y_predict_list = []\n",
    "    y_test_list = []\n",
    "    #预测，计算准确率并输出混淆矩阵\n",
    "    for one_test_data in test_data:\n",
    "        y_predict = decision_tree_predict(decision_tree,attribute_label,one_test_data)\n",
    "        y_test = one_test_data[-1]\n",
    "        y_predict_list.append(y_predict)\n",
    "        y_test_list.append(y_test)\n",
    "        if  y_predict == y_test:\n",
    "            count+=1\n",
    "    accuracy = count/len(test_data)\n",
    "    precision_macro1 = metrics.precision_score(y_test_list, y_predict_list, average='macro')\n",
    "    precision_micro1 = metrics.precision_score(y_test_list, y_predict_list, average='micro')\n",
    "    recall_macro1 = metrics.recall_score(y_test_list, y_predict_list, average='macro')\n",
    "    recall_micro1 = metrics.recall_score(y_test_list, y_predict_list, average='micro')\n",
    "    F1_measure_macro1 = metrics.f1_score(y_test_list, y_predict_list, average='macro')\n",
    "    F1_measure_micro1 = metrics.f1_score(y_test_list, y_predict_list, average='micro')\n",
    "    cm1 = confusion_matrix(y_test_list, y_predict_list)\n",
    "    print('决策树分类器的准确率为:', accuracy)\n",
    "    print('决策树分类器的宏平均精确率为:', precision_macro1)\n",
    "    print('决策树分类器的微平均精确率为:', precision_micro1)\n",
    "    print('决策树分类器的宏平均召回率为:', recall_macro1)\n",
    "    print('决策树分类器的微平均召回率为:', recall_micro1)\n",
    "    print('决策树分类器的宏平均F1-score为:', F1_measure_macro1)\n",
    "    print('决策树分类器的微平均F1-score为:', F1_measure_micro1)\n",
    "    print(\"混淆矩阵为:\\n\",cm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树分类器的准确率为: 0.9111111111111111\n",
      "决策树分类器的宏平均精确率为: 0.9138888888888889\n",
      "决策树分类器的微平均精确率为: 0.9111111111111111\n",
      "决策树分类器的宏平均召回率为: 0.9138888888888889\n",
      "决策树分类器的微平均召回率为: 0.9111111111111111\n",
      "决策树分类器的宏平均F1-score为: 0.9138888888888889\n",
      "决策树分类器的微平均F1-score为: 0.9111111111111111\n",
      "混淆矩阵为:\n",
      " [[14  0  0]\n",
      " [ 0 14  2]\n",
      " [ 0  2 13]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: scipy.sum is deprecated and will be removed in SciPy 2.0.0, use numpy.sum instead\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: scipy.sum is deprecated and will be removed in SciPy 2.0.0, use numpy.sum instead\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#划分数据集\n",
    "def load_data(ratio):\n",
    "    data = pd.read_csv(\"D2.data\",header=None)\n",
    "    data_set = np.array(data).tolist()\n",
    "    train_data, test_data = train_test_split(data_set,test_size = ratio)\n",
    "    return train_data,test_data\n",
    "\n",
    "#按类别划分数据\n",
    "def seprateByClass(dataset):\n",
    "    seprate_dict = {}\n",
    "    info_dict = {}\n",
    "    for vector in dataset:\n",
    "        if vector[-1] not in seprate_dict:\n",
    "            seprate_dict[vector[-1]] = []\n",
    "            info_dict[vector[-1]] = 0\n",
    "        seprate_dict[vector[-1]].append(vector)\n",
    "        info_dict[vector[-1]] +=1\n",
    "    return seprate_dict,info_dict\n",
    "\n",
    "#计算均值和方差\n",
    "def mean(list):\n",
    "    list = [float(x) for x in list] #字符串转数字\n",
    "    return sum(list)/float(len(list))\n",
    "def var(list):\n",
    "    list = [float(x) for x in list]\n",
    "    avg = mean(list)\n",
    "    var = sum([math.pow((x-avg),2) for x in list])/float(len(list)-1)\n",
    "    return var\n",
    "\n",
    "#计算每一个属性的均值和方差\n",
    "def summarizeAttribute(dataset):\n",
    "    dataset = np.delete(dataset,-1,axis = 1) # delete label\n",
    "    summaries = [(mean(attr),var(attr)) for attr in zip(*dataset)]\n",
    "    return summaries\n",
    "\n",
    "#按类别提取属性特征 \n",
    "def summarizeByClass(dataset):\n",
    "    dataset_separated,dataset_info = seprateByClass(dataset)\n",
    "    summarize_by_class = {}\n",
    "    for classValue, vector in dataset_separated.items():\n",
    "        summarize_by_class[classValue] = summarizeAttribute(vector)\n",
    "    return summarize_by_class\n",
    "\n",
    "#计算先验概率\n",
    "def calulateClassPriorProb(dataset,dataset_info):\n",
    "    dataset_prior_prob = {}\n",
    "    sample_sum = len(dataset)\n",
    "    for class_value, sample_nums in dataset_info.items():\n",
    "        dataset_prior_prob[class_value] = sample_nums/float(sample_sum)\n",
    "    return dataset_prior_prob\n",
    "\n",
    "#计算条件概率\n",
    "def calculateProb(x,mean,var):\n",
    "    exponent = math.exp(math.pow((x-mean),2)/(-2*var))\n",
    "    p = (1/math.sqrt(2*math.pi*var))*exponent\n",
    "    return p\n",
    "\n",
    "#计算类条件概率\n",
    "def calculateClassProb(input_data,train_Summary_by_class):\n",
    "    prob = {}\n",
    "    for class_value, summary in train_Summary_by_class.items():\n",
    "        prob[class_value] = 1\n",
    "        for i in range(len(summary)):\n",
    "            mean,var = summary[i]\n",
    "            x = input_data[i]\n",
    "            p = calculateProb(x,mean,var)\n",
    "        prob[class_value] *=p\n",
    "    return prob\n",
    "\n",
    "#单个样本预测\n",
    "def bayesianPredictOneSample(input_data):\n",
    "    prior_prob = calulateClassPriorProb(trainset,train_info)\n",
    "    train_Summary_by_class = summarizeByClass(trainset)\n",
    "    classprob_dict = calculateClassProb(input_data,train_Summary_by_class)\n",
    "    result = {}\n",
    "    for class_value,class_prob in classprob_dict.items():\n",
    "        p = class_prob*prior_prob[class_value]\n",
    "        result[class_value] = p\n",
    "    return max(result,key=result.get)\n",
    "\n",
    "#对测试集进行预测，并计算准确率\n",
    "def calculateAccByBeyesian(dataset):\n",
    "    correct = 0\n",
    "    predict_list = []\n",
    "    for vector in dataset:\n",
    "        input_data = vector[:-1]\n",
    "        label = vector[-1]\n",
    "        result = bayesianPredictOneSample(input_data)\n",
    "        predict_list.append(result)\n",
    "        if result == label:\n",
    "            correct+=1\n",
    "    return predict_list,correct/len(dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ratio = 0.3 #测试集的比例\n",
    "    trainset, testset =load_data(ratio)\n",
    "    train_separated,train_info = seprateByClass(trainset)\n",
    "    y_pre,acc = calculateAccByBeyesian(testset)\n",
    "    y_test = []\n",
    "    for item in testset:\n",
    "        y_test.append(item[-1])\n",
    "    cm2 = confusion_matrix(y_test, y_pre)\n",
    "    precision_macro2 = metrics.precision_score(y_test, y_pre, average='macro')\n",
    "    precision_micro2 = metrics.precision_score(y_test, y_pre, average='micro')\n",
    "    recall_macro2 = metrics.recall_score(y_test, y_pre, average='macro')\n",
    "    recall_micro2 = metrics.recall_score(y_test, y_pre, average='micro')\n",
    "    F1_measure_macro2 = metrics.f1_score(y_test, y_pre, average='macro')\n",
    "    F1_measure_micro2 = metrics.f1_score(y_test, y_pre, average='micro')\n",
    "    print('决策树分类器的准确率为:', acc)\n",
    "    print('决策树分类器的宏平均精确率为:', precision_macro2)\n",
    "    print('决策树分类器的微平均精确率为:', precision_micro2)\n",
    "    print('决策树分类器的宏平均召回率为:', recall_macro2)\n",
    "    print('决策树分类器的微平均召回率为:', recall_micro2)\n",
    "    print('决策树分类器的宏平均F1-score为:', F1_measure_macro2)\n",
    "    print('决策树分类器的微平均F1-score为:', F1_measure_micro2)\n",
    "    print(\"混淆矩阵为:\\n\",cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "x = np.arange(7)\n",
    "y1 = [accuracy, precision_macro1, precision_micro1, recall_macro1, recall_micro1, F1_measure_macro1, F1_measure_micro1]\n",
    "y2 = [acc, precision_macro2, precision_micro2, recall_macro2, recall_micro2, F1_measure_macro2, F1_measure_micro2]\n",
    "\n",
    "bar_width = 0.45\n",
    "tick_label = [\"Accuracy\", \"Precision_macro\", \"Precision_micro\", \"Recall_macro\", \"Recall_micro\", \"F1_measure_macro\", \"F1_measure_micro\"]\n",
    "\n",
    "plt.bar(x, y1, bar_width, align=\"center\", color=\"c\", label=\"DecisionTree\", alpha=0.5)\n",
    "plt.bar(x+bar_width, y2, bar_width, color=\"b\", align=\"center\", label=\"NaiveBayes\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"metrics\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.xticks(x+bar_width/2, tick_label)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('./D2_DT_NB.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
