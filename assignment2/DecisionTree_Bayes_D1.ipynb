{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:69: DeprecationWarning: scipy.sort is deprecated and will be removed in SciPy 2.0.0, use numpy.sort instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树分类器的准确率为: 0.8676236044657097\n",
      "决策树分类器的宏平均精确率为: 0.5633099318084598\n",
      "决策树分类器的微平均精确率为: 0.8676236044657097\n",
      "决策树分类器的宏平均召回率为: 0.5457043723900762\n",
      "决策树分类器的微平均召回率为: 0.8676236044657097\n",
      "决策树分类器的宏平均F1-score为: 0.5523738175861278\n",
      "决策树分类器的微平均F1-score为: 0.8676236044657096\n",
      "混淆矩阵为:\n",
      " [[189   1  86]\n",
      " [  0   0  34]\n",
      " [ 45   0 899]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "from scipy import *\n",
    "from math import log\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "#划分数据集\n",
    "def load_data(ratio):\n",
    "    data = pd.read_csv(\"new_D1.csv\",header=None)\n",
    "    data_set = np.array(data).tolist()\n",
    "    train_data, test_data = train_test_split(data_set,test_size = ratio)\n",
    "    return train_data,test_data\n",
    " \n",
    "\n",
    "#决策树的生成\n",
    "def generate_decision_tree(data_set ,attribute_label):\n",
    "    label_list = [entry[-1] for entry in data_set]\n",
    "    if label_list.count(label_list[0]) == len(label_list): #如果所有的数据都属于同一个类别，则返回该类别\n",
    "        return label_list[0]\n",
    "    if len(data_set[0]) == 1: #如果数据没有属性值数据，则返回该其中出现最多的类别作为分类\n",
    "        return most_voted_attribute(label_list)\n",
    "    best_attribute_index, best_split_point = attribute_selection_method(data_set)\n",
    "    best_attribute = attribute_label[best_attribute_index]\n",
    "    decision_tree = { best_attribute:{}}\n",
    "    del(attribute_label[best_attribute_index]) #找到最佳划分属性后需要将其从属性名列表中删除\n",
    "\n",
    "    #如果best_split_point为空，说明此时最佳划分属性的类型为离散值，否则为连续值\n",
    "    if best_split_point == None:\n",
    "        attribute_list = [entry[best_attribute_index] for entry in data_set]\n",
    "        attribute_set = set(attribute_list)\n",
    "        for attribute in attribute_set: #属性的各个值\n",
    "            sub_labels = attribute_label[:]\n",
    "            decision_tree[best_attribute][attribute] = generate_decision_tree(\n",
    "                split_data_set(data_set,best_attribute_index,attribute,continuous=False),sub_labels)\n",
    "    else:\n",
    "        #最佳划分属性类型为连续值，此时计算出的最佳划分点将数据集一分为二，划分字段取名为<=和>\n",
    "        sub_labels = attribute_label[:]\n",
    "        decision_tree[best_attribute][\"<=\"+str(best_split_point)] = generate_decision_tree(\n",
    "            split_data_set(data_set, best_attribute_index, best_split_point, True, 0), sub_labels)\n",
    "        sub_labels = attribute_label[:]\n",
    "        decision_tree[best_attribute][\">\" + str(best_split_point)] = generate_decision_tree(\n",
    "            split_data_set(data_set, best_attribute_index, best_split_point, True, 1), sub_labels)\n",
    "    return decision_tree\n",
    " \n",
    "#通过信息增益比来计算最佳划分属性\n",
    "def attribute_selection_method(data_set):\n",
    "    num_attributes = len(data_set[0])-1 #属性的个数，减1是因为去掉了标签\n",
    "    info_D = calc_info_D(data_set)  #香农熵\n",
    "    max_grian_rate = 0.0  #最大信息增益比\n",
    "    best_attribute_index = -1\n",
    "    best_split_point = None\n",
    "    continuous = False\n",
    "    for i in range(num_attributes):\n",
    "        attribute_list = [entry[i] for entry in data_set]  # 求属性列表，此时为连续值\n",
    "        info_A_D = 0.0  #特征A对数据集D的信息增益\n",
    "        split_info_D = 0.0  #数据集D关于特征A的值的熵\n",
    "        if attribute_list[0] not in set(['M','F','I']):\n",
    "            continuous = True\n",
    "        \"\"\"\n",
    "        属性为连续值，先对该属性下的所有离散值进行排序\n",
    "        然后每相邻的两个值之间的中点作为划分点计算信息增益比，对应最大增益比的划分点为最佳划分点\n",
    "        由于可能多个连续值可能相同，所以通过set只保留其中一个值\n",
    "        \"\"\"\n",
    "        if continuous == True:\n",
    "            attribute_list = sort(attribute_list)\n",
    "            temp_set = set(attribute_list) #通过set来剔除相同的值\n",
    "            attribute_list = [attr for attr in temp_set]\n",
    "            split_points = []\n",
    "            for index in range(len(attribute_list) - 1):\n",
    "                #求出各个划分点\n",
    "                split_points.append((float(attribute_list[index]) + float(attribute_list[index + 1])) / 2)\n",
    "            for split_point in split_points:#对划分点进行遍历\n",
    "                info_A_D = 0.0\n",
    "                split_info_D = 0.0\n",
    "                for part in range(2): #最佳划分点将数据一分为二，因此循环2次即可得到两段数据\n",
    "                    sub_data_set = split_data_set(data_set, i, split_point, True, part)\n",
    "                    prob = len(sub_data_set) / float(len(data_set))\n",
    "                    info_A_D += prob * calc_info_D(sub_data_set)\n",
    "                    split_info_D -= prob * log(prob, 2)\n",
    "                if split_info_D==0:\n",
    "                    split_info_D+=1\n",
    "                \n",
    "                #由于关于属性A的熵split_info_D可能为0，因此此处加1\n",
    "                \n",
    "                grian_rate = (info_D - info_A_D) / split_info_D #计算信息增益比\n",
    "                if grian_rate > max_grian_rate:\n",
    "                    max_grian_rate = grian_rate\n",
    "                    best_split_point = split_point\n",
    "                    best_attribute_index = i\n",
    "                    #print([best_attribute_index,best_split_point])\n",
    "        else: #划分属性为离散值\n",
    "            attribute_list = [entry[i] for entry in data_set]  # 求属性列表\n",
    "            attribute_set = set(attribute_list)\n",
    "            for attribute in attribute_set: #对每个属性进行遍历\n",
    "                sub_data_set = split_data_set(data_set, i, attribute, False)\n",
    "                prob = len(sub_data_set) / float(len(data_set))\n",
    "                info_A_D += prob * calc_info_D(sub_data_set)\n",
    "                split_info_D -= prob * log(prob, 2)\n",
    "            if split_info_D == 0:\n",
    "                split_info_D += 1\n",
    "            grian_rate = (info_D - info_A_D) / split_info_D #计算信息增益比\n",
    "            if grian_rate > max_grian_rate:\n",
    "                max_grian_rate = grian_rate\n",
    "                # print(max_grian_rate)\n",
    "                best_attribute_index = i\n",
    "                best_split_point = None  #如果最佳属性是离散值，此处将分割点置为空留作判定\n",
    " \n",
    "    return best_attribute_index,best_split_point\n",
    " \n",
    "#多数表决：返回标签列表中数量最大的类\n",
    "def most_voted_attribute(label_list):\n",
    "    label_nums = {}\n",
    "    for label in label_list:\n",
    "        if label in label_nums.keys():\n",
    "            label_nums[label] += 1\n",
    "        else:\n",
    "            label_nums[label] = 1\n",
    "    sorted_label_nums = sorted(label_nums.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_label_nums[0][0]\n",
    " \n",
    "#计算信息熵\n",
    "def calc_info_D(data_set):\n",
    "    num_entries = len(data_set)\n",
    "    label_nums = {} #为每个类别建立字典，value为对应该类别的数目\n",
    "    for entry in data_set:\n",
    "        label = entry[-1]\n",
    "        if label in label_nums.keys():\n",
    "            label_nums[label]+=1\n",
    "        else:\n",
    "            label_nums[label]=1\n",
    "    info_D = 0.0\n",
    "    for label in label_nums.keys():\n",
    "        prob = float(label_nums[label])/num_entries\n",
    "        info_D -= prob * log(prob,2)\n",
    "    return info_D\n",
    " \n",
    "\n",
    "#按属性划分子数据集，分为离散属性的划分与连续属性的划分\n",
    "def split_data_set(data_set, index, value, continuous, part=0):\n",
    "    res_data_set = []\n",
    "    if continuous == True:#划分的属性为连续值\n",
    "        for entry in data_set:\n",
    "            if part == 0 and float(entry[index])<= value: #求划分点左侧的数据集\n",
    "                reduced_entry = entry[:index]\n",
    "                reduced_entry.extend(entry[index + 1:]) #划分后去除数据中第index列的值\n",
    "                res_data_set.append(reduced_entry)\n",
    "            if part ==1 and float(entry[index])> value: #求划分点右侧的数据集\n",
    "                reduced_entry = entry[:index]\n",
    "                reduced_entry.extend(entry[index + 1:])\n",
    "                res_data_set.append(reduced_entry)\n",
    " \n",
    "    else: #划分的属性为离散值\n",
    "        for entry in data_set:\n",
    "            if entry[index] == value: #按数据集中第index列的值等于value的分数据集\n",
    "                reduced_entry = entry[:index]\n",
    "                reduced_entry.extend(entry[index+1:]) #划分后去除数据中第index列的值\n",
    "                res_data_set.append(reduced_entry)\n",
    "    return res_data_set\n",
    " \n",
    "\n",
    "#对一项测试数据进行预测，通过递归来预测该项数据的标签\n",
    "def decision_tree_predict(decision_tree, attribute_labels, one_test_data):\n",
    "    first_key = list(decision_tree.keys())[0]\n",
    "    second_dic = decision_tree[first_key]\n",
    "    attribute_index = attribute_labels.index(first_key)\n",
    "    res_label = None\n",
    "    for key in second_dic.keys(): #属性分连续值和离散值，连续值对应<=和>两种情况\n",
    "        if key[0] == '<':\n",
    "            value = float(key[2:])\n",
    "            if float(one_test_data[attribute_index])<= value:\n",
    "                if type(second_dic[key]).__name__ =='dict':\n",
    "                    res_label = decision_tree_predict(second_dic[key], attribute_labels, one_test_data)\n",
    "                else:\n",
    "                    res_label = second_dic[key]\n",
    "        elif key[0] == '>':\n",
    "            #print(key[1:])\n",
    "            value = float(key[1:])\n",
    "            if float(one_test_data[attribute_index]) > value:\n",
    "                if type(second_dic[key]).__name__ == 'dict':\n",
    "                    res_label = decision_tree_predict(second_dic[key], attribute_labels, one_test_data)\n",
    "                else:\n",
    "                    res_label = second_dic[key]\n",
    " \n",
    "        else:\n",
    "            if one_test_data[attribute_index] == key:\n",
    "                if type(second_dic[key]).__name__ =='dict':\n",
    "                    res_label = decision_tree_predict(second_dic[key], attribute_labels, one_test_data)\n",
    "                else:\n",
    "                    res_label = second_dic[key]\n",
    "    return res_label\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    ratio = 0.3 #测试集的比例\n",
    "    train_data, test_data =load_data(ratio)\n",
    "    attribute_label = ['Sex','Length','Diameter','Height','Whole_Weight','Shcked_Weight','Viscera_Weight','Shell_Weight']\n",
    "    decision_tree= generate_decision_tree(train_data,attribute_label)\n",
    "    #递归会改变attribute_label的值，此处再传一次\n",
    "    attribute_label = ['Sex', 'Length', 'Diameter', 'Height', 'Whole_Weight', 'Shcked_Weight', 'Viscera_Weight',\n",
    "                       'Shell_Weight']\n",
    "    count = 0\n",
    "    y_predict_list = []\n",
    "    y_test_list = []\n",
    "    #预测，计算准确率并输出混淆矩阵\n",
    "    for one_test_data in test_data:\n",
    "        y_predict = decision_tree_predict(decision_tree,attribute_label,one_test_data)\n",
    "        y_test = one_test_data[-1]\n",
    "        y_predict_list.append(y_predict)\n",
    "        y_test_list.append(y_test)\n",
    "        if  y_predict == y_test:\n",
    "            count+=1\n",
    "    accuracy = count/len(test_data)\n",
    "    precision_macro1 = metrics.precision_score(y_test_list, y_predict_list, average='macro')\n",
    "    precision_micro1 = metrics.precision_score(y_test_list, y_predict_list, average='micro')\n",
    "    recall_macro1 = metrics.recall_score(y_test_list, y_predict_list, average='macro')\n",
    "    recall_micro1 = metrics.recall_score(y_test_list, y_predict_list, average='micro')\n",
    "    F1_measure_macro1 = metrics.f1_score(y_test_list, y_predict_list, average='macro')\n",
    "    F1_measure_micro1 = metrics.f1_score(y_test_list, y_predict_list, average='micro')\n",
    "    cm1 = confusion_matrix(y_test_list, y_predict_list)\n",
    "    print('决策树分类器的准确率为:', accuracy)\n",
    "    print('决策树分类器的宏平均精确率为:', precision_macro1)\n",
    "    print('决策树分类器的微平均精确率为:', precision_micro1)\n",
    "    print('决策树分类器的宏平均召回率为:', recall_macro1)\n",
    "    print('决策树分类器的微平均召回率为:', recall_micro1)\n",
    "    print('决策树分类器的宏平均F1-score为:', F1_measure_macro1)\n",
    "    print('决策树分类器的微平均F1-score为:', F1_measure_micro1)\n",
    "    print(\"混淆矩阵为:\\n\",cm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 朴素贝叶斯分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#划分数据集\n",
    "def load_data(ratio):\n",
    "    data = pd.read_csv(\"new_D1.csv\",header=None)\n",
    "    data_set = np.array(data).tolist()\n",
    "    train_data, test_data = train_test_split(data_set,test_size = ratio)\n",
    "    return train_data,test_data\n",
    "\n",
    "#将数据集按照不同的类别划分\n",
    "def seprateByClass(dataset):\n",
    "    seprate_dict = {}\n",
    "    info_dict = {}\n",
    "    for vector in dataset:\n",
    "        if vector[-1] not in seprate_dict:\n",
    "            seprate_dict[vector[-1]] = []\n",
    "            info_dict[vector[-1]] = 0\n",
    "        seprate_dict[vector[-1]].append(vector)\n",
    "        info_dict[vector[-1]] +=1\n",
    "    return seprate_dict,info_dict\n",
    "\n",
    "#定义计算均值和方差的方法\n",
    "def mean(list):\n",
    "    list = [float(x) for x in list] #字符串转数字\n",
    "    return sum(list)/float(len(list))\n",
    "def var(list):\n",
    "    list = [float(x) for x in list]\n",
    "    avg = mean(list)\n",
    "    var = sum([math.pow((x-avg),2) for x in list])/float(len(list)-1)\n",
    "    return var\n",
    "\n",
    "#计算每个连续属性的均值和方差\n",
    "def summarizeAttribute(dataset):\n",
    "    dataset = np.delete(dataset,-1,axis = 1) # 删除标签\n",
    "    dataset = np.delete(dataset,0,axis = 1) # 删除离散属性\n",
    "    summaries = [(mean(attr),var(attr)) for attr in zip(*dataset)]\n",
    "    return summaries\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    dataset_separated,dataset_info = seprateByClass(dataset)\n",
    "    summarize_by_class = {}\n",
    "    for classValue, vector in dataset_separated.items():\n",
    "        summarize_by_class[classValue] = summarizeAttribute(vector)\n",
    "    return summarize_by_class\n",
    "\n",
    "#计算类条件概率\n",
    "def calulateClassPriorProb(dataset,dataset_info):\n",
    "    dataset_prior_prob = {}\n",
    "    sample_sum = len(dataset)\n",
    "    for class_value, sample_nums in dataset_info.items():\n",
    "        dataset_prior_prob[class_value] = sample_nums/float(sample_sum)\n",
    "    return dataset_prior_prob\n",
    "\n",
    "#计算离散值的条件概率\n",
    "def calculateProb(x,mean,var):\n",
    "    exponent = math.exp(math.pow((x-mean),2)/(-2*var))\n",
    "    p = (1/math.sqrt(2*math.pi*var))*exponent\n",
    "    return p\n",
    "\n",
    "#计算离散值的条件概率\n",
    "def calculateProb1(dataset):\n",
    "    train_separated,train_info = seprateByClass(dataset)\n",
    "    class_keys_list = list(train_info.keys())\n",
    "    class_values_list = list(train_info.values())\n",
    "    attri_list = []\n",
    "    p_list = []\n",
    "    for i in range(len(class_keys_list)):\n",
    "        for item in train_separated[class_keys_list[i]]:\n",
    "            attri_list.append(item[0])\n",
    "        attri_list = list(Counter(attri_list).values())\n",
    "        result = 1\n",
    "        for j in range(len(attri_list)):\n",
    "            p = attri_list[j] / class_values_list[i]\n",
    "            result *= p\n",
    "        p_list.append(result)\n",
    "    return p_list\n",
    "\n",
    "#类条件概率\n",
    "def calculateClassProb(dataset,input_data,train_Summary_by_class):\n",
    "    prob = {}\n",
    "    p_list = calculateProb1(dataset)\n",
    "    a = 0\n",
    "    for class_value, summary in train_Summary_by_class.items():\n",
    "        prob[class_value] = p_list[a]\n",
    "        a += 1\n",
    "        for i in range(len(summary)):\n",
    "            mean,var = summary[i]\n",
    "            x = input_data[i]\n",
    "            p = calculateProb(x,mean,var)\n",
    "        prob[class_value] *=p\n",
    "    return prob\n",
    "\n",
    "#对单个样本做预测\n",
    "def bayesianPredictOneSample(dataset, input_data):\n",
    "    prior_prob = calulateClassPriorProb(trainset,train_info)\n",
    "    train_Summary_by_class = summarizeByClass(trainset)\n",
    "    classprob_dict = calculateClassProb(dataset, input_data,train_Summary_by_class)\n",
    "    result = {}\n",
    "    for class_value,class_prob in classprob_dict.items():\n",
    "        p = class_prob*prior_prob[class_value]\n",
    "        result[class_value] = p\n",
    "    return max(result,key=result.get)\n",
    "\n",
    "#对测试集进行预测，并计算准确率\n",
    "def calculateAccByBeyesian(trainset, dataset):\n",
    "    correct = 0\n",
    "    predict_list = []\n",
    "    for vector in dataset:\n",
    "        input_data = vector[1:-1]\n",
    "        label = vector[-1]\n",
    "        result = bayesianPredictOneSample(trainset,input_data)\n",
    "        predict_list.append(result)\n",
    "        if result == label:\n",
    "            correct+=1\n",
    "    return predict_list,correct/len(dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ratio = 0.3 #测试集的比例\n",
    "    trainset, testset =load_data(ratio)\n",
    "    train_separated,train_info = seprateByClass(trainset)\n",
    "    y_pre,acc = calculateAccByBeyesian(trainset, testset)\n",
    "    y_test = []\n",
    "    for item in testset:\n",
    "        y_test.append(item[-1])\n",
    "    cm2 = confusion_matrix(y_test, y_pre)\n",
    "    precision_macro2 = metrics.precision_score(y_test, y_pre, average='macro')\n",
    "    precision_micro2 = metrics.precision_score(y_test, y_pre, average='micro')\n",
    "    recall_macro2 = metrics.recall_score(y_test, y_pre, average='macro')\n",
    "    recall_micro2 = metrics.recall_score(y_test, y_pre, average='micro')\n",
    "    F1_measure_macro2 = metrics.f1_score(y_test, y_pre, average='macro')\n",
    "    F1_measure_micro2 = metrics.f1_score(y_test, y_pre, average='micro')\n",
    "    print('朴素贝叶斯分类器的准确率为:', acc)\n",
    "    print('朴素贝叶斯分类器的宏平均精确率为:', precision_macro2)\n",
    "    print('朴素贝叶斯分类器的微平均精确率为:', precision_micro2)\n",
    "    print('朴素贝叶斯分类器的宏平均召回率为:', recall_macro2)\n",
    "    print('朴素贝叶斯分类器的微平均召回率为:', recall_micro2)\n",
    "    print('朴素贝叶斯分类器的宏平均F1-score为:', F1_measure_macro2)\n",
    "    print('朴素贝叶斯分类器的微平均F1-score为:', F1_measure_micro2)\n",
    "    print(\"混淆矩阵为:\\n\",cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "x = np.arange(7)\n",
    "y1 = [accuracy, precision_macro1, precision_micro1, recall_macro1, recall_micro1, F1_measure_macro1, F1_measure_micro1]\n",
    "y2 = [acc, precision_macro2, precision_micro2, recall_macro2, recall_micro2, F1_measure_macro2, F1_measure_micro2]\n",
    "\n",
    "bar_width = 0.45\n",
    "tick_label = [\"Accuracy\", \"Precision_macro\", \"Precision_micro\", \"Recall_macro\", \"Recall_micro\", \"F1_measure_macro\", \"F1_measure_micro\"]\n",
    "\n",
    "plt.bar(x, y1, bar_width, align=\"center\", color=\"c\", label=\"DecisionTree\", alpha=0.5)\n",
    "plt.bar(x+bar_width, y2, bar_width, color=\"b\", align=\"center\", label=\"NaiveBayes\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"metrics\")\n",
    "plt.ylabel(\"values\")\n",
    "\n",
    "plt.xticks(x+bar_width/2, tick_label)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('./D1_DT_NB.svg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
